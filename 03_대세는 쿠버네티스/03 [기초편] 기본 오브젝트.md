---
작성일 : 2020-11-08
강의 주소 : 인프런 - 대세는 쿠버네티스 ^o^ [초급~중급]
---

[TOC]

---

# 기본 오브젝트

## Pod -Container, Label, NodeSchedule

### Container

컨테이너 끼리 Port 같은 것 사용 불가

pot 생성시 **IP 자동할당** (외부에서 접근 불가) - **IP는 휘발성** 있음

![Pod with Container Port for Kubernetes](img/03%20%5B%EA%B8%B0%EC%B4%88%ED%8E%B8%5D%20%EA%B8%B0%EB%B3%B8%20%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/Pod%20with%20Container%20Port%20for%20Kubernetes.jpg)

- 한 Pod에 여러 컨테이너
- 컨테이너 이름은 p8000 (8000번 포트 open)
- 다른 컨테이너 이름은 p8080 (8080번 포트 open)

1.  #### Pod

    ```
    apiVersion: v1
    kind: Pod
    metadata:
      name: pod-1
    spec:
      containers:
      - name: container1
        image: kubetm/p8000
        ports:
        - containerPort: 8000
      - name: container2
        image: kubetm/p8080
        ports:
        - containerPort: 8080
    ```

    ![image-20201202205120898](img/03%20%5B%EA%B8%B0%EC%B4%88%ED%8E%B8%5D%20%EA%B8%B0%EB%B3%B8%20%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/image-20201202205120898.png)

    Dashboard에서 생성 후, 위와 같이 정보를 볼 수 있다.

    

    ![image-20201202205325392](img/03%20%5B%EA%B8%B0%EC%B4%88%ED%8E%B8%5D%20%EA%B8%B0%EB%B3%B8%20%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/image-20201202205325392.png)

    master에서 해당 pod에 대해 8000, 8080 포트로 접근 가능

    

    ![image-20201202205500114](img/03%20%5B%EA%B8%B0%EC%B4%88%ED%8E%B8%5D%20%EA%B8%B0%EB%B3%B8%20%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/image-20201202205500114.png)

    exec 버튼을 클릭해, pod의 container에 직접 접근 가능

    

    ![image-20201202205649689](img/03%20%5B%EA%B8%B0%EC%B4%88%ED%8E%B8%5D%20%EA%B8%B0%EB%B3%B8%20%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/image-20201202205649689.png)

    Container 1에서 같은 pod의 Container 2에 접근 가능

    

    >   ![image-20201202205957332](img/03%20%5B%EA%B8%B0%EC%B4%88%ED%8E%B8%5D%20%EA%B8%B0%EB%B3%B8%20%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/image-20201202205957332.png)
    >
    >   같은 pod에서 동일한 port의 Container를 만드려고 하면 위와 같이 실패해서 재생성 계속 시도.

2.  #### Replication

    >   Controller는 pod를 만들어주고 pod가 죽었을 때 다시 생성해주는 관리적 역할

    ```
    apiVersion: v1
    kind: ReplicationController
    metadata:
      name: replication-1
    spec:
      replicas: 1
      selector:
        app: rc
      template:
        metadata:
          name: pod-1
          labels:
            app: rc
        spec:
          containers:
          - name: container
            image: kubetm/init
    ```

    ![image-20201202210349012](img/03%20%5B%EA%B8%B0%EC%B4%88%ED%8E%B8%5D%20%EA%B8%B0%EB%B3%B8%20%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/image-20201202210349012.png)

    -   `replication-1-8srxn`을 삭제하면 바로 `replication-1-z4l6m`이 자동으로 생성됨.



### Label

![Pod with Label Selector for Kubernetes](img/03%20%5B%EA%B8%B0%EC%B4%88%ED%8E%B8%5D%20%EA%B8%B0%EB%B3%B8%20%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/Pod%20with%20Label%20Selector%20for%20Kubernetes.jpg)

**Label** : 목적에 따라 오브젝트들을 분류하고 분류된 오브젝트만 따로 관리

key :Value 로 나뉨

개발에서 돌아가는 web, db, server

상용에서 돌아가는 web, db, server로 나뉨

상용에 사용되는 라벨을 서비스에 원하는 pod를 붙여 사용하도록 만듬

1.  #### Pod

    ```yaml
    apiVersion: v1
    kind: Pod
    metadata:
      name: pod-1
      labels:
        type: web
        lo: dev
    spec:
      containers:
      - name: container
        image: kubetm/init
    ```

    ```yaml
    apiVersion: v1
    kind: Pod
    metadata:
      name: pod-2
      labels:
        type: db
        lo: dev
    spec:
      containers:
      - name: container
        image: kubetm/init
    ```

    ```yaml
    apiVersion: v1
    kind: Pod
    metadata:
      name: pod-3
      labels:
        type: server
        lo: dev
    spec:
      containers:
      - name: container
        image: kubetm/init
    ```

    ```yaml
    apiVersion: v1
    kind: Pod
    metadata:
      name: pod-4
      labels:
        type: web
        lo: production
    spec:
      containers:
      - name: container
        image: kubetm/init
    ```

    ```yaml
    apiVersion: v1
    kind: Pod
    metadata:
      name: pod-5
      labels:
        type: db
        lo: production
    spec:
      containers:
      - name: container
        image: kubetm/init
    ```

    ```yaml
    apiVersion: v1
    kind: Pod
    metadata:
      name: pod-6
      labels:
        type: server
        lo: production
    spec:
      containers:
      - name: container
        image: kubetm/init
    ```

2.  #### Service

    ```yaml
    apiVersion: v1
    kind: Service
    metadata:
      name: svc-for-web
    spec:
      selector:
        type: web
      ports:
      - port: 8080
    ```

    ![image-20201202211202340](img/03%20%5B%EA%B8%B0%EC%B4%88%ED%8E%B8%5D%20%EA%B8%B0%EB%B3%B8%20%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/image-20201202211202340.png)

    -   `Type: web`인 pod들이 연결됨을 확인.

    

    ```yaml
    apiVersion: v1
    kind: Service
    metadata:
      name: svc-for-prod
    spec:
      selector:
        lo: production
      ports:
      - port: 8080
    ```

    ![image-20201202211332579](img/03%20%5B%EA%B8%B0%EC%B4%88%ED%8E%B8%5D%20%EA%B8%B0%EB%B3%B8%20%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/image-20201202211332579.png)

    -   `lo: production`인 pod들이 연결됨을 확인.

> 나중에 서비스를 구동할 때 Selector에 있는 라벨에 해당하는 Pod들만 연결이 됨



### Node Schedule

Pod는 여러 노드들 중 하나에 올라가야하는데

직접 선택하는 방법과 자동으로 선택되는 것이 있음

![Pod with Node Schedule for Kubernetes](img/03%20%5B%EA%B8%B0%EC%B4%88%ED%8E%B8%5D%20%EA%B8%B0%EB%B3%B8%20%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/Pod%20with%20Node%20Schedule%20for%20Kubernetes.jpg)

1.  #### 직접 선택

    ```yaml
    apiVersion: v1
    kind: Pod
    metadata:
      name: pod-3
    spec:
      nodeSelector:
        kubernetes.io/hostname: k8s-node1
      containers:
      - name: container
        image: kubetm/init
    ```

    ![image-20201202211742313](img/03%20%5B%EA%B8%B0%EC%B4%88%ED%8E%B8%5D%20%EA%B8%B0%EB%B3%B8%20%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/image-20201202211742313.png)

    -   k8s-node1의 레이블에서 node생성할 때 nodeSelector와 동일한 게 있다.

        

    ![image-20201202212013768](img/03%20%5B%EA%B8%B0%EC%B4%88%ED%8E%B8%5D%20%EA%B8%B0%EB%B3%B8%20%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/image-20201202212013768.png)

    -   k8s-node1 에 생성됨.

        

2.  #### 스케쥴러 판단

    <img src="img/03%20%5B%EA%B8%B0%EC%B4%88%ED%8E%B8%5D%20%EA%B8%B0%EB%B3%B8%20%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/image-20201202212333280.png" alt="image-20201202212333280" style="zoom:50%;" /><img src="img/03%20%5B%EA%B8%B0%EC%B4%88%ED%8E%B8%5D%20%EA%B8%B0%EB%B3%B8%20%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/image-20201202212351681.png" alt="image-20201202212351681" style="zoom:50%;" />

    Node1은 메모리가 부족하고 Node2는 여유롭다.

    ```yaml
    apiVersion: v1
    kind: Pod
    metadata:
      name: pod-5
    spec:
      containers:
      - name: container
        image: kubetm/init
        resources:
          requests:
            memory: 2Gi
          limits:
            memory: 3Gi
    ```

    

- Memory 초과시 pod 종료시킴
- Cpu 초과시 request로 낮춤, Over시에도 종료되지 않음

>   CPU가 limits 수치까지 올라갔다고 해서 무조건 Request 수치까지 core를 낮추는 것이 아니고, Node의 전체 부하 상태가 OverCommit된 상태일때 동작합니다. Node 위의 Pod들이 Node의 자원을 모두 사용하고도 그 이상을 자원을 요구하게 되었을 때 Limit 수치까지 CPU를 사용하고 있는 Pod들에 한해서 그 수치를 Reqeust까지 떨어뜨리게 되며 Memory의 경우에도 그러한 상태일때 Limit까지 올라간 Pod들에 한해 재기동 시키게 됩니다. 

## Service - ClusterIP, NodePort, LoadBalancer

서비스는 기본적으로 자신의 클러스터 iP를 가지고 있고 pod를 연결시켜놓으면 서비스로부터 pod 접근가능.

서비스를 통해서 접근하는 이유 : pod는 언제든지 장애로 죽을 수 있고 재생성 되는데 IP가 변할 수 있기 때문

서비스는 사용자가 직접 지우지 않는 이상, 지워지지 않아 항상 접근 할 수 있음

서비스의 종류가 다양함. (pod 접근 방식 바뀜)

### Service 종류 _ClusterIP_

![image-20201108231030892](img/03%20%5B%EA%B8%B0%EC%B4%88%ED%8E%B8%5D%20%EA%B8%B0%EB%B3%B8%20%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/image-20201108231030892.png)

- 외부에서 접근 할 수 없지만, 클러스터 내에서는 접근 가능
- 한 서비스에서 여러 pod 연결 가능
- 서비스가 트래픽 분산해서 전달
- type 생략 시 기본값으로 설정됨
- targetPort는 사용될 서비스의 pod port를 의미함

인가된 사용자(운영자) - 외부에서 접근 불가, 내부에서만 사용할 수 있음

작업 : 쿠버네티스 내부 대시보드 관리

작업 : pod의 서비스 상태 디버깅

### Service 종류 _NodePort_

![image-20201108231359185](img/03%20%5B%EA%B8%B0%EC%B4%88%ED%8E%B8%5D%20%EA%B8%B0%EB%B3%B8%20%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/image-20201108231359185.png)

- ClusterIP의 성격 + a
- 모든 노드에 똑같은 port가 할당되어 노드의 IP, Port로 접근하면 서비스로 연결됨
- pod가 있는 노드 뿐아니라 모든 노드에 port할당됨
- 1번 노드로 접근해도 서비스가 2번 pod로 전달해주기도 함
- externalTrafficPolicy 설정이 되어있다면 노드로 직접 접근시 접근한 노드로 서비스 전달

내부망 연결

데모나 임시 연결용 - 내부적인 개발을 하다가 잠깐 보일때

### Service 종류 _Load Balancer_

![image-20201108231614648](img/03%20%5B%EA%B8%B0%EC%B4%88%ED%8E%B8%5D%20%EA%B8%B0%EB%B3%B8%20%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/image-20201108231614648.png)

- NodePort의 성격 + a
- Load Balancer가 생성되지만 외부 플러그인이 설치되어있어야지 외부 IP 지원

외부 시스템 노출용 (서비스 배포)

### Service - 실습



## Volume - emptyDir, hostPath, PV/PVC

### emptyDir

![image-20201108232303655](img/03%20%5B%EA%B8%B0%EC%B4%88%ED%8E%B8%5D%20%EA%B8%B0%EB%B3%B8%20%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/image-20201108232303655.png)

- 컨테이너들끼리 데이터 공유
- 최초 볼륨 생성될 떄 볼륨이 비어있어서 empty
- 두 컨테이너가 볼륨을 마운트 해놓으면 컨테이너가 자연스럽게 공유 할 수 있음
- Pod 생성시 만들어지고 삭제시 없어져서 일시적인 내용을 담을 때 사용할 수 있도록.
- 컨테이너1은 /mount1, 컨테이너2는 /mount2이지만 실질적인 mount는 똑같음

### hostPath

![image-20201108232612775](img/03%20%5B%EA%B8%B0%EC%B4%88%ED%8E%B8%5D%20%EA%B8%B0%EB%B3%B8%20%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/image-20201108232612775.png)

- pod가 죽어도 data가 살아지지 않음
- pod2가 죽어서 재생성되었는데 다른 노드에서 생성된다면, node-v1의 폴륨을 사용할 수 없음
- 대신 node추가시마다 Moun걸어주면 할 수 있음(쿠버네티스가 해주는 기능이 아니라 귀찮음)
- pod자신이 할당되어있는 host의 파일을 읽고 쓸때 (설정 파일 등)
- host-path라는 이름의 볼륨과 속성.
- 사전에 해당 Node에 경로가 있어야함.
- 하드에 데이터 저장용 X
- 노드에 있는 데이터를 pod에서 쓰기위함 O



### PV/PVC

![image-20201108232944823](img/03%20%5B%EA%B8%B0%EC%B4%88%ED%8E%B8%5D%20%EA%B8%B0%EB%B3%B8%20%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/image-20201108232944823.png)

- pod의 영속성 개념 제공
- aws, git 등 다른 곳의 volume을 사용하는 경우, persistent volume(PV)을 통해 PVC를 두어 pod를 연결
- User, Admin으로 나뉨
- User는 pod개발자
- Admin은 쿠버네티스 관리자
- PVC를 이용해 관리자에게 요청하는 느낌
- claimName에 PVC네임을 입력함
- PV정의 생성 - PVC 생성 - PV 연결 - pod생성시 PVC 마운트



### Volume - 실습



## ConfigMap, Secret - Env, Mount

### ConfigMap, Secret

![image-20201108233358521](img/03%20%5B%EA%B8%B0%EC%B4%88%ED%8E%B8%5D%20%EA%B8%B0%EB%B3%B8%20%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/image-20201108233358521.png)

- 개발환경과 상용환경에서 보안 설정 등 때문에 똑같은 이미지를 2개 가지는 건 비효율적
- 환경에 따라 옵션 변경할 수 있게 하는 것이 ConfigMap과 Secret
- 똑같은 Container를 이용해 두 환경에 사용가능

### Env (Literal 상수)

![image-20201108233617747](img/03%20%5B%EA%B8%B0%EC%B4%88%ED%8E%B8%5D%20%EA%B8%B0%EB%B3%B8%20%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/image-20201108233617747.png)

- 환경변수를 이용해서 하는 방법
- PW, key는 Secret에 저장됨. base64로 변환해서 저장해야함(메모리에 저장되어 보안이 좋음 1Mbyte 제한)



### Env (File)

![image-20201108233803731](img/03%20%5B%EA%B8%B0%EC%B4%88%ED%8E%B8%5D%20%EA%B8%B0%EB%B3%B8%20%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/image-20201108233803731.png)

- 파일 이름이 Key이므로
- dashboard에서 지원하지 않기때문에 bash이용해서 만들어야함
- file.txt 내용이 base64로 인코딩됨
- 환경변수의 이름은 **file** 
- configMap의 내용이 변해도 pod Content 변경되지 않음(죽어서 재생성되면 바뀜)

### Mount

![image-20201108233908985](img/03%20%5B%EA%B8%B0%EC%B4%88%ED%8E%B8%5D%20%EA%B8%B0%EB%B3%B8%20%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/image-20201108233908985.png)

- file을 configMap에 넣는 것 까지는 똑같음.
- pod만들때 mount path정함 
- configMap의 내용이 변하면 pod Content 변경

### ConfigMap, Sercret - 실습



## Namespace, ResourceQuota, LimitRange

![image-20201108234216467](img/03%20%5B%EA%B8%B0%EC%B4%88%ED%8E%B8%5D%20%EA%B8%B0%EB%B3%B8%20%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/image-20201108234216467.png)

쿠버네티스 클러스터 전체 자원 (메모리, CPU 등)

네임스페이스들이 다양하고 pod도 많은데 특정 네임스페이스 pod가 완전히 사용하면 다른 pod이 사용불가하기 때문에

pod의 자원이 Quota 이상 자원을 사용할 수 없게 막아주는 기능.

Limit Range를 둬서 들어올 pod의 크기를 조정할 수 있음



### Namespace

![image-20201108234419008](img/03%20%5B%EA%B8%B0%EC%B4%88%ED%8E%B8%5D%20%EA%B8%B0%EB%B3%B8%20%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/image-20201108234419008.png)

- 한 네임스페이스에서 같은 이름의 pod를 지정할 수 없음
- 타 네임스페이스의 자원과 분리되서 관리됨.
- 네임스페이스를 지우면 그 내부 자원들도 모두 제거됨.
- 타 네임스페이스에서 pod가 접근시 접근은 가능
- 네임스페이스는 이름만 지정
- selector와 label이 같아도 연결되지 않음



### ResourceQuota

![image-20201108234604497](img/03%20%5B%EA%B8%B0%EC%B4%88%ED%8E%B8%5D%20%EA%B8%B0%EB%B3%B8%20%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/image-20201108234604497.png)

- 네임스페이스의 자원한계를 설정 (메모리, cpu, storage)
- request와 limits으로 나눔.
- pod생성시 무조건 스펙을 지정해야함.
- 새로운 pod가 스펙이 없거나 넘어서면 들어올 수 없음.



### LimitRange

![image-20201108234821509](img/03%20%5B%EA%B8%B0%EC%B4%88%ED%8E%B8%5D%20%EA%B8%B0%EB%B3%B8%20%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/image-20201108234821509.png)

- 각각의 pod가 들어올 때 해당 네임스페이스에 들어올 수 있는지 체크
- pod에서 생성되는 메모리 min, max와 maxLimitRequestRatio 리밋과 request 배율 값
- defaultRequest, default는 설정되지 않은 pod에 들어감.
- 각각의 pod마다 지원되는 옵션 다름.



### Namespace, ResourceQuota, LimitRange - 실습

